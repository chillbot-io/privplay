"""LLM verification for uncertain PHI/PII detections."""

from abc import ABC, abstractmethod
from typing import Optional
import logging
import httpx

from ..types import VerificationResponse, VerificationResult, EntityType
from ..config import get_config, VerificationConfig

logger = logging.getLogger(__name__)


# ============================================================
# IMPROVED VERIFICATION PROMPT
# ============================================================
# Key improvements:
# 1. More specific examples for common FP cases
# 2. Explicit guidance on what IS and ISN'T PHI
# 3. Structured thinking before answer
# 4. Healthcare-specific context awareness

VERIFICATION_PROMPT = """You are a PHI/PII detection expert for healthcare applications. Determine if a flagged term is Protected Health Information (PHI) or Personally Identifiable Information (PII).

CONTEXT:
"{context}"

FLAGGED TERM: "{entity}"
DETECTED AS: {entity_type}

DECISION GUIDE:

IS PHI/PII (answer YES):
- Specific person names (John Smith, Dr. Johnson, Mary)
- Government IDs (SSN, driver's license, passport numbers)
- Contact info (specific phone numbers, email addresses, physical addresses)
- Medical record numbers, account numbers
- Dates tied to individuals (DOB, admission date, discharge date)
- Biometric identifiers
- Device serial numbers tied to patients

NOT PHI/PII (answer NO):
- Generic terms (patient, doctor, nurse, unit, department)
- Medical unit names (ICU, MICU, ER, OR, Building 4, Room 101)
- Generic roles without names (the attending, the resident)
- Browser/software identifiers (Mozilla, Safari, Windows, Chrome, Gecko)
- Version numbers (5.0, 537.36, 10.15.7)
- Generic greetings (Hello, Dear, Hi there)
- Common words that happen to match patterns
- Dates without individual context (policy effective dates, general timestamps)
- Generic location references (downtown clinic, main hospital)

Think step by step:
1. Is this a SPECIFIC identifier for a REAL individual?
2. Could this actually identify or contact someone?
3. Is this just a generic/common term or technical string?

Answer with ONLY: YES or NO"""


# Lighter prompt for high-confidence verifications (faster)
QUICK_VERIFICATION_PROMPT = """Is "{entity}" (flagged as {entity_type}) actual PHI/PII that identifies a specific person?

Context: "{context}"

Consider: Browser strings (Mozilla, Safari, Gecko), greetings (Hello, Dear), generic terms (patient, ICU), and version numbers are NOT PHI.

Answer ONLY: YES or NO"""


class Verifier(ABC):
    """Base interface for LLM verification."""

    @abstractmethod
    def verify(
        self,
        entity_text: str,
        entity_type: EntityType,
        context: str
    ) -> VerificationResponse:
        """Ask LLM if entity is PHI in context."""
        pass

    @abstractmethod
    def is_available(self) -> bool:
        """Check if verifier is ready."""
        pass


class OllamaVerifier(Verifier):
    """Verify using local Ollama server."""

    def __init__(
        self, 
        url: str = "http://localhost:11434", 
        model: str = "phi3:mini",
        use_quick_prompt: bool = False,
        timeout: int = 30,
    ):
        self.url = url.rstrip("/")
        self.model = model
        self.use_quick_prompt = use_quick_prompt
        self.timeout = timeout
        self._available: Optional[bool] = None

    def verify(
        self,
        entity_text: str,
        entity_type: EntityType,
        context: str,
        quick: bool = None,
    ) -> VerificationResponse:
        """Ask Ollama if entity is PHI."""
        if not self.is_available():
            return VerificationResponse(
                decision=VerificationResult.UNCERTAIN,
                confidence=0.5,
                reasoning="Ollama not available"
            )

        # Choose prompt based on quick flag
        use_quick = quick if quick is not None else self.use_quick_prompt
        prompt_template = QUICK_VERIFICATION_PROMPT if use_quick else VERIFICATION_PROMPT
        
        # Truncate context if too long (keep it focused)
        max_context = 500
        if len(context) > max_context:
            # Try to center around the entity
            entity_pos = context.find(entity_text)
            if entity_pos >= 0:
                start = max(0, entity_pos - max_context // 2)
                end = min(len(context), entity_pos + len(entity_text) + max_context // 2)
                context = "..." + context[start:end] + "..."
            else:
                context = context[:max_context] + "..."

        prompt = prompt_template.format(
            context=context,
            entity=entity_text,
            entity_type=entity_type.value
        )

        try:
            response = httpx.post(
                f"{self.url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,  # Low temp for consistent answers
                        "num_predict": 20,   # We only need YES/NO + maybe brief reason
                        "top_p": 0.9,
                    }
                },
                timeout=float(self.timeout)
            )
            response.raise_for_status()

            result = response.json()
            answer = result.get("response", "").strip().upper()

            # Parse response - look for YES or NO
            # Handle various response formats
            answer_clean = answer.replace(".", "").replace(",", "").strip()
            first_word = answer_clean.split()[0] if answer_clean.split() else ""

            if first_word == "YES" or answer_clean.startswith("YES"):
                return VerificationResponse(
                    decision=VerificationResult.YES,
                    confidence=0.90,
                    reasoning="LLM confirmed as PHI/PII"
                )
            elif first_word == "NO" or answer_clean.startswith("NO"):
                return VerificationResponse(
                    decision=VerificationResult.NO,
                    confidence=0.90,
                    reasoning="LLM rejected as not PHI/PII"
                )
            else:
                # Try to extract YES/NO from anywhere in response
                if "YES" in answer and "NO" not in answer:
                    return VerificationResponse(
                        decision=VerificationResult.YES,
                        confidence=0.75,
                        reasoning=f"LLM likely confirmed: {answer[:50]}"
                    )
                elif "NO" in answer and "YES" not in answer:
                    return VerificationResponse(
                        decision=VerificationResult.NO,
                        confidence=0.75,
                        reasoning=f"LLM likely rejected: {answer[:50]}"
                    )
                else:
                    return VerificationResponse(
                        decision=VerificationResult.UNCERTAIN,
                        confidence=0.5,
                        reasoning=f"LLM unclear: {answer[:50]}"
                    )

        except httpx.TimeoutException:
            logger.warning(f"Ollama verification timed out for: {entity_text[:30]}")
            return VerificationResponse(
                decision=VerificationResult.UNCERTAIN,
                confidence=0.5,
                reasoning="Verification timed out"
            )
        except Exception as e:
            logger.error(f"Ollama verification failed: {e}")
            return VerificationResponse(
                decision=VerificationResult.UNCERTAIN,
                confidence=0.5,
                reasoning=f"Error: {str(e)}"
            )

    def verify_batch(
        self,
        items: list,  # List of (entity_text, entity_type, context) tuples
    ) -> list:
        """Verify multiple entities (sequential, could be parallelized later)."""
        results = []
        for entity_text, entity_type, context in items:
            result = self.verify(entity_text, entity_type, context, quick=True)
            results.append(result)
        return results

    def is_available(self) -> bool:
        """Check if Ollama is running and model is available."""
        if self._available is not None:
            return self._available

        try:
            # Check if Ollama is running
            response = httpx.get(f"{self.url}/api/tags", timeout=5.0)
            response.raise_for_status()

            # Check if model is available
            models = response.json().get("models", [])
            model_names = [m.get("name", "") for m in models]

            # Check for exact match or partial match
            if any(self.model in name or name in self.model for name in model_names):
                self._available = True
                logger.info(f"Ollama model {self.model} is available")
            else:
                logger.warning(f"Model {self.model} not found. Available: {model_names}")
                logger.info(f"Pull with: ollama pull {self.model}")
                self._available = False

            return self._available

        except Exception as e:
            logger.debug(f"Ollama not available: {e}")
            self._available = False
            return False

    def pull_model(self) -> bool:
        """Pull the model if not available."""
        try:
            logger.info(f"Pulling model {self.model}...")
            response = httpx.post(
                f"{self.url}/api/pull",
                json={"name": self.model, "stream": False},
                timeout=600.0  # 10 min timeout for download
            )
            response.raise_for_status()
            self._available = True
            logger.info(f"Successfully pulled {self.model}")
            return True
        except Exception as e:
            logger.error(f"Failed to pull model: {e}")
            return False

    def reset_availability_cache(self):
        """Reset cached availability check."""
        self._available = None


class RemoteVerifier(Verifier):
    """Verify using remote OpenAI-compatible API."""

    def __init__(self, url: str, api_key: str, model: str):
        self.url = url.rstrip("/")
        self.api_key = api_key
        self.model = model

    def verify(
        self,
        entity_text: str,
        entity_type: EntityType,
        context: str
    ) -> VerificationResponse:
        """Ask remote LLM if entity is PHI."""
        # Truncate context if needed
        max_context = 500
        if len(context) > max_context:
            context = context[:max_context] + "..."
            
        prompt = VERIFICATION_PROMPT.format(
            context=context,
            entity=entity_text,
            entity_type=entity_type.value
        )

        try:
            response = httpx.post(
                f"{self.url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.1,
                    "max_tokens": 20,
                },
                timeout=30.0
            )
            response.raise_for_status()

            result = response.json()
            answer = result["choices"][0]["message"]["content"].strip().upper()

            if "YES" in answer and "NO" not in answer:
                return VerificationResponse(
                    decision=VerificationResult.YES,
                    confidence=0.90,
                    reasoning="LLM confirmed as PHI"
                )
            elif "NO" in answer and "YES" not in answer:
                return VerificationResponse(
                    decision=VerificationResult.NO,
                    confidence=0.90,
                    reasoning="LLM rejected as not PHI"
                )
            else:
                return VerificationResponse(
                    decision=VerificationResult.UNCERTAIN,
                    confidence=0.5,
                    reasoning=f"LLM unclear: {answer[:50]}"
                )

        except Exception as e:
            logger.error(f"Remote verification failed: {e}")
            return VerificationResponse(
                decision=VerificationResult.UNCERTAIN,
                confidence=0.5,
                reasoning=f"Error: {str(e)}"
            )

    def is_available(self) -> bool:
        """Check if remote API is configured."""
        return bool(self.url and self.api_key and self.model)


class NoopVerifier(Verifier):
    """Skip LLM verification - everything goes to human review."""

    def verify(
        self,
        entity_text: str,
        entity_type: EntityType,
        context: str
    ) -> VerificationResponse:
        return VerificationResponse(
            decision=VerificationResult.UNCERTAIN,
            confidence=0.5,
            reasoning="LLM verification disabled"
        )

    def is_available(self) -> bool:
        return True


def get_verifier(config: Optional[VerificationConfig] = None) -> Verifier:
    """Factory function to get appropriate verifier."""
    if config is None:
        config = get_config().verification

    if config.provider == "none":
        return NoopVerifier()

    if config.provider == "remote":
        return RemoteVerifier(
            url=config.remote.url,
            api_key=config.remote.api_key,
            model=config.remote.model
        )

    # Default to Ollama
    return OllamaVerifier(
        url=config.ollama.url,
        model=config.ollama.model
    )
